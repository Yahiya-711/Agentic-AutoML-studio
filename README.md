# ğŸ¤– Agentic AutoML Studio

> **The world's first privacy-first, agentic AutoML system delivered as a portable Docker container â€” your data never leaves your machine.**

[![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)](https://python.org)
[![FLAML](https://img.shields.io/badge/AutoML-FLAML%20(Microsoft)-orange)](https://github.com/microsoft/FLAML)
[![LangGraph](https://img.shields.io/badge/Orchestration-LangGraph-green)](https://github.com/langchain-ai/langgraph)
[![Ollama](https://img.shields.io/badge/LLM-DeepSeek--R1%20(Local)-purple)](https://ollama.com)
[![Docker](https://img.shields.io/badge/Deployment-Docker-2496ED?logo=docker)](https://docker.com)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)
[![Privacy](https://img.shields.io/badge/Data%20Privacy-100%25%20Local-brightgreen)]()

---

## ğŸ¯ The Problem This Solves

Every major AutoML platform today â€” Google AutoML, AWS SageMaker, Azure AutoML, H2O Cloud â€” has one thing in common: **your data leaves your machine and travels to their servers.**

This is not just a privacy preference. It is a legal problem:

- **GDPR** (EU): Fines of up to â‚¬20M per violation. â‚¬5.65 billion issued since 2018.
- **HIPAA** (US Healthcare): Patient records cannot leave hospital networks.
- **US CLOUD Act**: Requires US cloud providers to hand data to authorities on demand â€” even data stored abroad belonging to foreign citizens.
- **India DPDP Act, Brazil LGPD, China PIPL**: Each mandates local data storage with strict cross-border transfer restrictions.
- **Gartner forecast**: By 2027, 70% of enterprises adopting generative AI will consider digital sovereignty a top concern when selecting a provider.

**Agentic AutoML Studio is the answer**: a fully self-contained, AI-powered AutoML system that runs entirely on your hardware. No cloud. No data transfer. No compliance risk. Pull the Docker image and own your ML pipeline.

---

## âœ¨ What Makes This Unique

### The Core Innovation: Agentic Architecture + Local AI

Every other AutoML tool is a **fixed pipeline** â€” a deterministic sequence of steps with no reasoning.

This project introduces **three autonomous AI agents** powered by a local open-source LLM (DeepSeek-R1 via Ollama) that reason, act, and self-correct:

```
Standard AutoML:
  Load â†’ Train â†’ Show Result
  (if model is broken: YOU figure it out)

Agentic AutoML Studio:
  Load â†’ Agent Plans â†’ Agent Trains â†’ Agent Audits â†’
  [if data leakage found: Agent names bad columns + retrains] â†’
  Show verified, clean results
```

The **Auditor agent** is the first LLM-powered automated data leakage detector integrated into an AutoML pipeline. It catches the silent killer of ML models â€” ID columns, target proxies, future data â€” automatically.

### vs. Every Other AutoML Framework

| Feature | Google AutoML | H2O Cloud | AutoSklearn | AutoGluon | **This Project** |
|---------|:------------:|:---------:|:-----------:|:---------:|:---------------:|
| Data stays local | âŒ | âŒ | âœ… | âœ… | âœ… **Guaranteed** |
| Agentic AI reasoning | âŒ | âŒ | âŒ | âŒ | âœ… **3 LLM Agents** |
| Auto leakage detection | âŒ | âŒ | âŒ | âŒ | âœ… **Auditor Agent** |
| Self-correcting retrain | âŒ | âŒ | âŒ | âŒ | âœ… **Auto-loop** |
| Open-source local LLM | âŒ | âŒ | âŒ | âŒ | âœ… **DeepSeek-R1** |
| Docker BaaS deployment | âŒ | âŒ | âŒ | âŒ | âœ… **One command** |
| GPU required | No | No | No | Recommended | âœ… **No** |
| GDPR / HIPAA safe | âŒ | âŒ | âœ… | âœ… | âœ… **By design** |
| Cost per run | $$$  | $$$ | Free | Free | âœ… **Free** |

---

## ğŸ—ï¸ Architecture

### Three-Agent System

```
User uploads CSV
      â”‚
      â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            AGENTIC AUTOML STUDIO                â•‘
â•‘                                                 â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚  ğŸ§  ORCHESTRATOR AGENT (DeepSeek-R1)     â”‚   â•‘
â•‘  â”‚                                          â”‚   â•‘
â•‘  â”‚  Reads column names + data types         â”‚   â•‘
â•‘  â”‚  Understands user's business goal        â”‚   â•‘
â•‘  â”‚  Decides: target column, metric,         â”‚   â•‘
â•‘  â”‚  task type (classification/regression)   â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                     â”‚ Structured Plan            â•‘
â•‘                     â–¼                           â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚  âš™ï¸  ENGINEER AGENT (FLAML AutoML)       â”‚   â•‘
â•‘  â”‚                                          â”‚   â•‘
â•‘  â”‚  Trains LightGBM, XGBoost, RandomForest  â”‚   â•‘
â•‘  â”‚  CatBoost, LogisticRegression + more     â”‚   â•‘
â•‘  â”‚  Returns ranked leaderboard +            â”‚   â•‘
â•‘  â”‚  feature importance scores               â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                     â”‚ Results                    â•‘
â•‘                     â–¼                           â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘  â”‚  ğŸ” AUDITOR AGENT (DeepSeek-R1)          â”‚   â•‘
â•‘  â”‚                                          â”‚   â•‘
â•‘  â”‚  Inspects top features semantically      â”‚   â•‘
â•‘  â”‚  TYPE 1: ID columns (customer_id)        â”‚   â•‘
â•‘  â”‚  TYPE 2: Target proxies (churn_flag)     â”‚   â•‘
â•‘  â”‚  TYPE 3: Future data (cancel_date)       â”‚   â•‘
â•‘  â”‚  Names bad columns â†’ triggers retrain    â”‚   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                     â”‚                           â•‘
â•‘            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â•‘
â•‘            â–¼ Approved          â–¼ Leakage Found  â•‘
â•‘          [END]          Exclude bad columns      â•‘
â•‘       Show results      Loop to Engineer         â•‘
â•‘                         (max 2 retries)          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      â”‚
      â–¼
Streamlit Dashboard:
â€¢ Model Leaderboard  â€¢ Feature Importance  â€¢ Audit Report
```

### Technology Stack Explained

| Component | Technology | Rationale |
|-----------|-----------|-----------|
| **Reasoning agents** | DeepSeek-R1:1.5b via Ollama | Open-source, 1.1GB, runs on CPU, 128K context |
| **AutoML engine** | FLAML (Microsoft Research) | Outperforms H2O/AutoSklearn under time budgets at 10% resource cost |
| **Agent orchestration** | LangGraph | Stateful conditional loops â€” impossible with simple pipelines |
| **Frontend** | Streamlit | Full web UI in pure Python, no JS required |
| **Containerization** | Docker + Compose | Portable, reproducible, one-command deploy |
| **Privacy guarantee** | 100% local stack | No external API calls, no telemetry, air-gap compatible |

---

## ğŸ”’ Privacy-First by Technical Design

This is not a marketing claim. It is enforced at the architecture level:

**No external network calls:** Ollama serves the LLM locally. FLAML trains locally. LangChain tracing is explicitly disabled (`LANGCHAIN_TRACING_V2=false`). Streamlit telemetry is disabled.

**No data persistence:** Uploaded CSVs are written to `/tmp/` (RAM-backed tmpfs on Linux). They are never written to a database, object store, or log file.

**Air-gap compatible:** After the one-time `docker pull` and `ollama pull deepseek-r1:1.5b`, the system runs with zero internet connectivity. Suitable for classified or sensitive environments.

**Audit trail:** Every agent decision is logged locally in the dashboard's Audit Report tab. You can see exactly what the LLM reasoned, what it flagged, and why.

```
GDPR Article 25:  âœ… Privacy by design and by default
HIPAA Â§164.312:   âœ… No PHI transmission outside network perimeter
India DPDP Act:   âœ… Data residency guaranteed (your hardware)
US CLOUD Act:     âœ… Not applicable (no US cloud provider involved)
```

---

## ğŸš€ BaaS: AutoML as a Business Service

### The Vision

Pull the Docker image. Run it on your server, laptop, or air-gapped workstation. Give any business user a URL. They upload a CSV and get a verified ML model â€” with no data scientist, no cloud account, no compliance review needed.

```bash
# One command. Any machine. Full ML pipeline.
docker-compose up

# Your data stays on your machine.
# Your model stays on your machine.
# Your insights stay in your business.
```

### Who Needs This

| Sector | Pain Point | How This Solves It |
|--------|-----------|-------------------|
| **Hospitals / Clinics** | Patient data cannot leave network | Runs inside hospital firewall, no cloud needed |
| **Banks / Credit Unions** | Transaction data is PCI-DSS regulated | Local Docker image, zero external transmission |
| **Law Firms** | Client data is legally privileged | Air-gap compatible, no external API |
| **EU SMEs** | Cannot afford GDPR compliance risk | No cloud = no cross-border transfer = no liability |
| **Government Agencies** | Citizen data sovereignty requirements | Fully sovereign â€” runs on government hardware |
| **Manufacturing** | Production IP in sensor data | No cloud exposure of proprietary process data |

### Deployment Models

```
Model 1 â€” Developer / Researcher:
  git clone + docker-compose up
  Full control, runs on your laptop

Model 2 â€” Enterprise On-Premise:
  docker pull company-registry/automl-studio
  docker-compose up
  Deployed inside corporate firewall

Model 3 â€” Air-Gapped / Classified:
  docker save â†’ USB â†’ docker load
  ollama pull (pre-downloaded model weights)
  Zero internet required after initial setup

Model 4 â€” Multi-Tenant (Roadmap):
  Isolated namespaces per business unit
  REST API for programmatic access
  Scheduled retraining on new data
```

---

## ğŸ“¦ Quick Start

### Prerequisites

| Requirement | Minimum | Notes |
|-------------|---------|-------|
| RAM | 8 GB | 5GB for container + 1.5GB Ollama + OS |
| CPU | 4 threads | No GPU required |
| Disk | 10 GB free | Docker image ~3GB + model 1.1GB |
| OS | Linux / macOS | Windows via WSL2 |
| Docker | 20.10+ | `docker --version` to check |

### Step 1: Install Ollama (Host Machine â€” Outside Docker)

```bash
# Linux / macOS
curl -fsSL https://ollama.com/install.sh | sh

# Pull model once (1.1 GB download)
ollama pull deepseek-r1:1.5b

# Start Ollama â€” keep this terminal open
ollama serve
```

### Step 2: Clone and Start

```bash
git clone https://github.com/YOUR_USERNAME/agentic-automl-studio.git
cd agentic-automl-studio

# First launch: builds image (~8 mins), downloads base layers
# Subsequent launches: ~10 seconds (all cached)
docker-compose up --build
```

### Step 3: Use the Dashboard

Open **http://localhost:8501** in your browser.

1. Upload any CSV file
2. (Optional) Describe what you want to predict
3. Adjust training time in the sidebar (30â€“120 seconds)
4. Click **Run Agentic Pipeline**
5. Watch three agents reason, train, and self-correct in real time

### Management Commands

```bash
# Stop the container (keeps image cached for fast restart)
docker-compose down

# View live logs from agents
docker-compose logs -f

# Restart after changes to code
docker-compose up --build

# Check container health
docker ps  # STATUS should show "healthy"

# Remove everything (forces full rebuild next time)
docker-compose down --rmi all --volumes
```

---

## ğŸ§ª Testing the Agentic Loop

```bash
# Generate test datasets
python3 -c "
from sklearn.datasets import load_breast_cancer
import pandas as pd

cancer = load_breast_cancer(as_frame=True).frame

# Test 1: Clean data â€” Auditor should approve on first pass
cancer.to_csv('data/test_clean.csv', index=False)

# Test 2: Leaky data â€” Auditor should flag and trigger retrain
leaky = cancer.copy()
leaky['patient_id'] = range(len(leaky))       # TYPE 1: ID column
leaky['target_proxy'] = leaky['target'] * 0.99 # TYPE 2: target proxy
leaky.to_csv('data/test_leaky.csv', index=False)

print('Test files ready: data/test_clean.csv and data/test_leaky.csv')
"
```

Upload `test_leaky.csv` â†’ expected behavior:
- Auditor flags `patient_id` (ID column) and `target_proxy` (proxy)
- Pipeline retrains without those columns
- Audit Report shows: `excluded_columns: ['patient_id', 'target_proxy']`, `retry_count: 1`
- Final model score will be **lower but honest** â€” no more cheating

---

## ğŸ“Š Performance

Benchmarked on i5-7th Gen, 8GB RAM, Linux Mint, no GPU â€” the most constrained realistic hardware:

| Dataset | Rows | Pipeline Time | RAM Peak | Verdict |
|---------|------|---------------|----------|---------|
| Breast Cancer (clean) | 569 | ~95s | 3.8 GB | âœ… Approved, 1 pass |
| Breast Cancer (leaky) | 569 | ~165s | 4.1 GB | âœ… Leakage caught, retrained |
| Titanic (binary) | 891 | ~110s | 3.5 GB | âœ… Approved, 1 pass |
| Iris (multiclass) | 150 | ~75s | 3.2 GB | âœ… Approved, 1 pass |

---

## ğŸ“ Project Structure

```
Agentic-AutoML-Studio/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ state.py          # Shared memory (TypedDict) across agents
â”‚   â”‚   â”œâ”€â”€ orchestrator.py   # LLM Agent: plans ML task from schema
â”‚   â”‚   â”œâ”€â”€ engineer.py       # FLAML Agent: trains and ranks models
â”‚   â”‚   â”œâ”€â”€ auditor.py        # LLM Agent: detects leakage, triggers retrain
â”‚   â”‚   â””â”€â”€ graph.py          # LangGraph: wires agents + conditional loop
â”‚   â””â”€â”€ ui/
â”‚       â””â”€â”€ dashboard.py      # Streamlit frontend
â”œâ”€â”€ data/                     # Docker volume (uploaded CSVs)
â”œâ”€â”€ Dockerfile                # Container build instructions
â”œâ”€â”€ docker-compose.yml        # Full stack + resource limits
â”œâ”€â”€ .dockerignore             # Keeps image lean (~3GB not ~5GB)
â”œâ”€â”€ docker_check.py           # Docker vs native environment detection
â”œâ”€â”€ main.py                   # Entry point + preflight checks
â”œâ”€â”€ requirements.txt          # Pinned Python dependencies
â””â”€â”€ README.md
```

---

## ğŸ”¬ Research Foundation

| Paper | Key Insight | How Used |
|-------|------------|----------|
| [AutoML to Date and Beyond (ACM 2021)](https://dl.acm.org/doi/abs/10.1145/3470918) | Defined 7-tier autonomy taxonomy | This project targets Level 4+ (self-correcting) |
| [Trust in AutoML (ACM IUI 2020)](https://dl.acm.org/doi/abs/10.1145/3377325.3377501) | Leaderboard + importance = highest trust | Dashboard design centered on these |
| [Whither AutoML? (ACM CHI 2021)](https://dl.acm.org/doi/abs/10.1145/3411764.3445306) | Partnership > full automation | Auditor provides human-like judgment |
| [FLAML (Microsoft 2021)](https://github.com/microsoft/FLAML) | 10% resource, equal/better performance | Core AutoML engine choice |
| [Auto-Sklearn (NeurIPS 2015)](https://papers.neurips.cc/paper/5872) | Algorithm selection under time budgets | Mathematical basis of Engineer agent |

---

## ğŸ—ºï¸ Roadmap

- [x] **v1.0** â€” Three-agent pipeline + Docker + Leakage detection
- [ ] **v1.1** â€” Explainer agent (LLM plain-English model summary)
- [ ] **v1.1** â€” Model export (`.pkl` download from dashboard)
- [ ] **v1.2** â€” REST API mode (`POST /api/train` endpoint)
- [ ] **v2.0** â€” Multi-tenant namespaces + model registry
- [ ] **v2.0** â€” Federated learning (train across sites, no data sharing)

---

## ğŸ“„ License

MIT â€” free to use, modify, and deploy in commercial products.

---

<div align="center">

**â­ Star this repo if you believe ML should be private by default**

*Built to prove that privacy-first AI and cutting-edge AutoML are not mutually exclusive.*

</div>
